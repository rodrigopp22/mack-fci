{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwxHf3E81Qyz"
   },
   "source": [
    "**COMPILADORES - AULA 05**\n",
    "\n",
    "**Prof. Luciano Silva**\n",
    "\n",
    "**OBJETIVOS DA AULA:**\n",
    "\n",
    "\n",
    "\n",
    "*   Entender e praticar com o algoritmo de análise sintática [ LALR(1) ] da ferramenta rply\n",
    "*   Entender e praticar com processo de detecção de erros de análise sintática\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbWUx55j1tLM",
    "outputId": "93249cdf-f74d-4551-8126-e4a0bef28088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rply in /home/digopp/.local/lib/python3.8/site-packages (0.7.8)\n",
      "Requirement already satisfied: appdirs in /home/digopp/.local/lib/python3.8/site-packages (from rply) (1.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDogT1ytJrEt"
   },
   "source": [
    "**ALGORITMO DE ANÁLISE SINTÁTICA LALR(1)**\n",
    "\n",
    "Anteriormente, implementamos um analisador sintático completo para o comando de atribuição com expressões ariméticas envolvendo números inteiros sem sinal:\n",
    "\n",
    "\\<atrib\\>::= ID \"=\" \\<expression\\>\n",
    "\n",
    "\\<expression\\> ::= NUMBER\n",
    "\n",
    "       | \\<expression\\> \"+\" \\<expression\\>\n",
    " \n",
    "       | \\<expression\\> \"-\" \\<expression\\>\n",
    " \n",
    "       | \\<expression\\> \"*\" \\<expression\\>\n",
    " \n",
    "       | \\<expression\\> \"/\" \\<expression\\>\n",
    " \n",
    "       | \"(\" <expression> \")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACSuZUyEJ2oQ"
   },
   "source": [
    "O primeiro passo foi implementar um analisador léxico para esta gramática, mostrado abaixo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AohGQ2yWKDli"
   },
   "outputs": [],
   "source": [
    "from rply import LexerGenerator\n",
    "\n",
    "lg = LexerGenerator()\n",
    "\n",
    "lg.add('ID', r'[a-zA-Z][a-zA-Z0-9]*')\n",
    "lg.add('EQUALS', r'=')\n",
    "lg.add('NUMBER', r'\\d+')\n",
    "lg.add('PLUS', r'\\+')\n",
    "lg.add('MINUS', r'-')\n",
    "lg.add('MUL', r'\\*')\n",
    "lg.add('DIV', r'/')\n",
    "lg.add('OPEN_PARENS', r'\\(')\n",
    "lg.add('CLOSE_PARENS', r'\\)')\n",
    "\n",
    "lg.ignore('\\s+')\n",
    "\n",
    "lexer = lg.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ricXOj1eH7Da"
   },
   "source": [
    "O segundo passo foi implementar as classes em Python para representar os nós da árvore sintática gerada pelo analisador sintático:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RLcu5RuHDl6B"
   },
   "outputs": [],
   "source": [
    "from rply.token import BaseBox\n",
    "\n",
    "class Number(BaseBox):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def eval(self):\n",
    "        return self.value\n",
    "\n",
    "class BinaryOp(BaseBox):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "class Add(BinaryOp):\n",
    "    def eval(self):\n",
    "        return self.left.eval() + self.right.eval()\n",
    "\n",
    "class Sub(BinaryOp):\n",
    "    def eval(self):\n",
    "        return self.left.eval() - self.right.eval()\n",
    "\n",
    "class Mul(BinaryOp):\n",
    "    def eval(self):\n",
    "        return self.left.eval() * self.right.eval()\n",
    "\n",
    "class Div(BinaryOp):\n",
    "    def eval(self):\n",
    "        return self.left.eval() / self.right.eval()\n",
    "\n",
    "class Attrib(BaseBox):\n",
    "    def __init__(self, id, expression):\n",
    "        self.id = id\n",
    "        self.expression = expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OEfEiOCIVxX"
   },
   "source": [
    "Finalmente, foi implementado o analisado sintático para o comando de atribuição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2MB_wWwWEGcX"
   },
   "outputs": [],
   "source": [
    "from rply import ParserGenerator\n",
    "\n",
    "pg = ParserGenerator(\n",
    "    # A list of all token names, accepted by the lexer.\n",
    "    ['NUMBER', 'OPEN_PARENS', 'CLOSE_PARENS',\n",
    "     'PLUS', 'MINUS', 'MUL', 'DIV','ID','EQUALS'\n",
    "    ],\n",
    "    # A list of precedence rules with ascending precedence, to\n",
    "    # disambiguate ambiguous production rules.\n",
    "    precedence=[\n",
    "        ('left', ['PLUS', 'MINUS']),\n",
    "        ('left', ['MUL', 'DIV'])    \n",
    "    ]\n",
    ")\n",
    "\n",
    "# regra <atrib>::= ID \"=\" <expression>\n",
    "\n",
    "@pg.production('atrib : ID EQUALS expression')\n",
    "def attrib(p):\n",
    "  return Attrib(p[0].getstr(),p[2])\n",
    "\n",
    "@pg.production('expression : NUMBER')\n",
    "def expression_number(p):\n",
    "    # p is a list of the pieces matched by the right hand side of the\n",
    "    # rule\n",
    "    return Number(int(p[0].getstr()))\n",
    "\n",
    "@pg.production('expression : OPEN_PARENS expression CLOSE_PARENS')\n",
    "def expression_parens(p):\n",
    "    return p[1]\n",
    "\n",
    "@pg.production('expression : expression PLUS expression')\n",
    "@pg.production('expression : expression MINUS expression')\n",
    "@pg.production('expression : expression MUL expression')\n",
    "@pg.production('expression : expression DIV expression')\n",
    "def expression_binop(p):\n",
    "    left = p[0]\n",
    "    right = p[2]\n",
    "    if p[1].gettokentype() == 'PLUS':\n",
    "        return Add(left, right)\n",
    "    elif p[1].gettokentype() == 'MINUS':\n",
    "        return Sub(left, right)\n",
    "    elif p[1].gettokentype() == 'MUL':\n",
    "        return Mul(left, right)\n",
    "    elif p[1].gettokentype() == 'DIV':\n",
    "        return Div(left, right)\n",
    "    else:\n",
    "        raise AssertionError('Oops, this should not be possible!')\n",
    "\n",
    "parser = pg.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaWSNLQeJG8F"
   },
   "source": [
    "Realizamos um teste com um comando de atribuição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f9H91s7fFWdB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Attrib object at 0x7f37f1f0ad30>\n",
      "x\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "arvore=parser.parse(lexer.lex('x=1+2*3'))\n",
    "print(arvore)\n",
    "print(arvore.id)\n",
    "print(arvore.expression.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp5zx9gB-92G"
   },
   "source": [
    "O algoritmo de análise sintática utilizado pela ferramenta rply é o LALR(1). Esta sigla significa que:\n",
    "\n",
    "*   o analisador irá olhar (**LOOK AHEAD**), no máximo, um token da entrada para decidir qual regra gramatical irá aplicar\n",
    "*   o analisador irá analisar a entrada da esquerda para a direita **(L)** e fará as reduções o mais à direita **(R)** possível. \n",
    "\n",
    "Para entender como esta algoritmo funciona, vamos utilizar a ferramenta online abaixo:\n",
    "\n",
    "https://fiona.dmcs.pl/tk/jsmachines.sourceforge.net/machines/lalr1.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smwo0iReAi_a"
   },
   "source": [
    "**EXERCÍCIO**\n",
    "\n",
    "Simular o algoritmo LALR(1) com a gramática fornecida no início desta aula, na ferramenta fornecida acima:\n",
    "\n",
    "\\<atrib\\>::= ID \"=\" \\<expression\\>\n",
    "\n",
    "\\<expression\\> ::= NUMBER\n",
    "\n",
    "   | \\<expression\\> \"+\" \\<expression\\>\n",
    " \n",
    "   | \\<expression\\> \"-\" \\<expression\\>\n",
    " \n",
    "   | \\<expression\\> \"*\" \\<expression\\>\n",
    " \n",
    "   | \\<expression\\> \"/\" \\<expression\\>\n",
    " \n",
    "   | \"(\" \\<expression\\> \")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUÇÃO**\n",
    "\n",
    "PROG -> EXPR\n",
    "\n",
    "EXPR -> TERMO + TERMO\n",
    "\n",
    "EXPR -> TERMO - TERMO\n",
    "\n",
    "TERMO -> FATOR * FATOR\n",
    "\n",
    "TERMO -> FATOR / FATOR\n",
    "\n",
    "FATOR -> num\n",
    "\n",
    "FATOR -> ( EXPR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWVdPe3TCOIa"
   },
   "source": [
    "**DETECÇÃO DE ERROS NO PROCESSO DE ANÁLISE SINTÁTICA**\n",
    "\n",
    "Vamos, inicialmente, tentar fazer a análise sintática da seguinte entrada:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dtKvqRzPCeha"
   },
   "outputs": [
    {
     "ename": "ParsingError",
     "evalue": "(None, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParsingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aef6d1cd9764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marvore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x=1+2*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/rply/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokenizer, state)\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For now, error_handler must raise.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mParsingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookahead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsourcepos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatestack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParsingError\u001b[0m: (None, None)"
     ]
    }
   ],
   "source": [
    "arvore=parser.parse(lexer.lex('x=1+2*'))\n",
    "print(arvore)\n",
    "print(arvore.id)\n",
    "print(arvore.expression.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0Rn_nnuCsZW"
   },
   "source": [
    "Observem que, nesta entrada, está faltando um segundo operando para a operação de multiplicação. Na ocorrência de um erro, por default, é gerada uma exceção do tipo **ParsingError**. Para tornar o processo mais amigável com o programador, podemos associar um detector de erros sintáticos ao nosso analisador sintático.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "usevjMbxDw5z"
   },
   "outputs": [],
   "source": [
    "from rply import ParserGenerator\n",
    "\n",
    "pg = ParserGenerator(\n",
    "    # A list of all token names, accepted by the lexer.\n",
    "    ['NUMBER', 'OPEN_PARENS', 'CLOSE_PARENS',\n",
    "     'PLUS', 'MINUS', 'MUL', 'DIV','ID','EQUALS'\n",
    "    ],\n",
    "    # A list of precedence rules with ascending precedence, to\n",
    "    # disambiguate ambiguous production rules.\n",
    "    precedence=[\n",
    "        ('left', ['PLUS', 'MINUS']),\n",
    "        ('left', ['MUL', 'DIV'])    \n",
    "    ]\n",
    ")\n",
    "\n",
    "@pg.error\n",
    "def error_handler(token):\n",
    "    raise ValueError(\"Token wasn't expected\")\n",
    "\n",
    "# regra <atrib>::= ID \"=\" <expression>\n",
    "\n",
    "@pg.production('atrib : ID EQUALS expression')\n",
    "def attrib(p):\n",
    "  return Attrib(p[0].getstr(),p[2])\n",
    "\n",
    "@pg.production('expression : NUMBER')\n",
    "def expression_number(p):\n",
    "    # p is a list of the pieces matched by the right hand side of the\n",
    "    # rule\n",
    "    return Number(int(p[0].getstr()))\n",
    "\n",
    "@pg.production('expression : OPEN_PARENS expression CLOSE_PARENS')\n",
    "def expression_parens(p):\n",
    "    return p[1]\n",
    "\n",
    "@pg.production('expression : expression PLUS expression')\n",
    "@pg.production('expression : expression MINUS expression')\n",
    "@pg.production('expression : expression MUL expression')\n",
    "@pg.production('expression : expression DIV expression')\n",
    "def expression_binop(p):\n",
    "    left = p[0]\n",
    "    right = p[2]\n",
    "    if p[1].gettokentype() == 'PLUS':\n",
    "        return Add(left, right)\n",
    "    elif p[1].gettokentype() == 'MINUS':\n",
    "        return Sub(left, right)\n",
    "    elif p[1].gettokentype() == 'MUL':\n",
    "        return Mul(left, right)\n",
    "    elif p[1].gettokentype() == 'DIV':\n",
    "        return Div(left, right)\n",
    "    else:\n",
    "        raise AssertionError('Oops, this should not be possible!')\n",
    "\n",
    "parser = pg.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "a36ssGXEEJ08"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Erro no token NUMBER na posição SourcePosition(idx=4, lineno=1, colno=5) com o valor 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5fad0bdf0966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marvore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x=1 2*3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marvore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/rply/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokenizer, state)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f99fbac2308b>\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Erro no token {} na posição {} com o valor {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettokentype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsourcepos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# regra <atrib>::= ID \"=\" <expression>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Erro no token NUMBER na posição SourcePosition(idx=4, lineno=1, colno=5) com o valor 2."
     ]
    }
   ],
   "source": [
    "arvore=parser.parse(lexer.lex('x=1 2*3'))\n",
    "print(arvore)\n",
    "print(arvore.id)\n",
    "print(arvore.expression.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WMu5EBNFseu"
   },
   "source": [
    "**EXERCÍCIO**\n",
    "\n",
    "Refatore o método error_handler(token) para imprimir todas as informações do token, para facilitar a intepretação do erro pelos programadores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DVb_BT5-F_ng"
   },
   "outputs": [],
   "source": [
    "#implemente sua solução aqui\n",
    "from rply import ParserGenerator\n",
    "\n",
    "pg = ParserGenerator(\n",
    "    # A list of all token names, accepted by the lexer.\n",
    "    ['NUMBER', 'OPEN_PARENS', 'CLOSE_PARENS',\n",
    "     'PLUS', 'MINUS', 'MUL', 'DIV','ID','EQUALS'\n",
    "    ],\n",
    "    # A list of precedence rules with ascending precedence, to\n",
    "    # disambiguate ambiguous production rules.\n",
    "    precedence=[\n",
    "        ('left', ['PLUS', 'MINUS']),\n",
    "        ('left', ['MUL', 'DIV'])    \n",
    "    ]\n",
    ")\n",
    "\n",
    "@pg.error\n",
    "def error_handler(token):\n",
    "    raise ValueError(\"Erro no token {} na posição {} com o valor {}.\".format(token.gettokentype(), token.getsourcepos(), token.getstr()))\n",
    "\n",
    "# regra <atrib>::= ID \"=\" <expression>\n",
    "\n",
    "@pg.production('atrib : ID EQUALS expression')\n",
    "def attrib(p):\n",
    "  return Attrib(p[0].getstr(),p[2])\n",
    "\n",
    "@pg.production('expression : NUMBER')\n",
    "def expression_number(p):\n",
    "    # p is a list of the pieces matched by the right hand side of the\n",
    "    # rule\n",
    "    return Number(int(p[0].getstr()))\n",
    "\n",
    "@pg.production('expression : OPEN_PARENS expression CLOSE_PARENS')\n",
    "def expression_parens(p):\n",
    "    return p[1]\n",
    "\n",
    "@pg.production('expression : expression PLUS expression')\n",
    "@pg.production('expression : expression MINUS expression')\n",
    "@pg.production('expression : expression MUL expression')\n",
    "@pg.production('expression : expression DIV expression')\n",
    "def expression_binop(p):\n",
    "    left = p[0]\n",
    "    right = p[2]\n",
    "    if p[1].gettokentype() == 'PLUS':\n",
    "        return Add(left, right)\n",
    "    elif p[1].gettokentype() == 'MINUS':\n",
    "        return Sub(left, right)\n",
    "    elif p[1].gettokentype() == 'MUL':\n",
    "        return Mul(left, right)\n",
    "    elif p[1].gettokentype() == 'DIV':\n",
    "        return Div(left, right)\n",
    "    else:\n",
    "        raise AssertionError('Oops, this should not be possible!')\n",
    "\n",
    "parser = pg.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym-pGbeCGD1v"
   },
   "source": [
    "**ATIVIDADE EAD**\n",
    "\n",
    "Refatore a implementação do analisador sintático para a linguagem TINY-C para incluir detecção de erros de compilação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92imM3KuGblM"
   },
   "outputs": [],
   "source": [
    "#implemente sua solução a partir daqui.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Cópia de COMPILADORES-AULA 5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
